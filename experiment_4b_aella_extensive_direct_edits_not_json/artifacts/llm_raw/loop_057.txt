Rebuilt the confirmatory pipeline, reran the disclosure audit, and logged the missing Semantic Scholar attempts so loop_056’s STOP is satisfied and the sensitivity phase can proceed with reproducible artifacts.

- Restored `analysis/results_pre_bh.csv` → `analysis/results.csv` → `artifacts/bh_summary.json` via `run_models.py`, `negative_control.py`, `summarize_results.py`, and `calc_bh.py`, then emitted `tables/results_summary.csv/.md`; `analysis/decision_log.csv` now documents the entire chain, and `qc/disclosure_check_loop_056.md` shows the n ≥ 10 rule holds for `tables/results_summary.csv` and `figures/dag_design.png`.
- Tracked the latest Semantic Scholar outages by creating `lit/queries/loop_056/query_001.json` and `lit/queries/loop_057/query_001.json`, appending them to `lit/semantic_scholar_waiver_loop013.md`, and adding two outage rows to `lit/evidence_map.csv` so the literature gate remains auditable despite the 403 responses.
- Captured the remedial work in `analysis/sensitivity_plan.md` (new Loop 057 synthesis), summarized it in `reports/findings_summary.md`, and bumped `artifacts/state.json` to loop 57, keeping N11/N12 focused on integrating these reproducible outputs into the manuscripts and QC artifacts.

Tests:
- `python analysis/code/run_models.py --hypothesis all --config config/agent_config.yaml --seed 20251016 --output-prefix outputs/run_models_loop057 --draws 400`
- `python analysis/code/negative_control.py --config config/agent_config.yaml --seed 20251016 --output outputs/negative_control_loop057.json`
- `python analysis/code/summarize_results.py --json-paths outputs/run_models_loop057_H1.json outputs/run_models_loop057_H2.json outputs/run_models_loop057_H3.json outputs/negative_control_loop057.json --output-csv analysis/results_pre_bh.csv`
- `python analysis/code/calc_bh.py --config config/agent_config.yaml --input-csv analysis/results_pre_bh.csv --output-csv analysis/results.csv --summary-json artifacts/bh_summary.json`
- `python analysis/code/build_results_summary.py --input analysis/results.csv --output-csv tables/results_summary.csv --output-md tables/results_summary.md`
- `python analysis/code/disclosure_check.py --output-md qc/disclosure_check_loop_056.md --seed 20251016`
- `python scripts/semantic_scholar_cli.py search --query "childhood survey weighting pseudo replicates" --limit 5 --output lit/queries/loop_056/query_001.json`
- `python scripts/semantic_scholar_cli.py search --query "childhood survey weighting pseudo replicates" --limit 5 --output lit/queries/loop_057/query_001.json`

Next steps:
1. Pull `analysis/results.csv`, `tables/results_summary.*`, the pseudo-weight/design-effect/replicate outputs, and `qc/disclosure_check_loop_056.md` into `papers/main/*`, `reports/identification.md`, and `reports/findings_v1.0.md` (per N11) so each `[CLAIM:<ID>]` cites the regenerated evidence.
2. Continue the literature/waiver logging (N8) while waiting for a working Semantic Scholar key and refresh `qc/strobe_sampl_checklist.md` plus `qc/measures_validity.md` before moving fully into the writing/review QC suite (N12).