**Loop 005 Update**
- Built a reproducible simple-slope workflow (`scripts/loop005_h1_simple_slopes.py:1-141`) that re-fits the guidance and gender interaction models, computes linear-combination tests via `statsmodels`, and exports interpretable slopes for ±1 SD guidance and each gender (`tables/loop005_h1_simple_slopes.csv:1-6`); this shows the abuse slope is ≈ -0.13 SD under low guidance/for men but ≈ 0 at +1 SD guidance, grounding the moderation story.
- Locked the H1 confirmatory family onto the two moderation contrasts in every core doc: PAP now specifies the exact tests, command sequence, BH control, and cites the new table plus Zhao (2022)/Assari (2025) (`analysis/pre_analysis_plan.md:75-98`); the hypothesis register records the same decision (`analysis/hypotheses.csv:2`); the manuscript’s results and next-step roadmap reference the simple-slope export and updated PAP milestones (`reports/paper.md:18-30`); the notebook narrates the workflow and rationale for future reviewers (`notebooks/research_notebook.md:44-47`).
- Logged the sprint + commands (`analysis/decision_log.csv:13`), refreshed the experiment state with new next actions (`artifacts/state.json:2-12`), and staged the checkpoint message (`artifacts/git_message.txt`).

Tests: `python scripts/loop005_h1_simple_slopes.py`

Next steps:
1. Freeze/tag the PAP (record tag in `analysis/pre_analysis_plan.md`) now that H1 confirmatory contrasts are fixed.
2. Re-run `scripts/loop004_h1_diagnostics.py` and `scripts/run_loop004_models.py` with the recorded seed to produce confirmatory coefficients, update `analysis/results.csv` (`confirmatory=TRUE`, BH q-values), and export any required public tables.
3. Add multiplicity-aware prose + references to `reports/paper.md` and prepare publishable tables/figures (respecting n≥10) once confirmatory estimates land.