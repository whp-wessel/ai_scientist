{"files":[{"path":"analysis/code/confirmatory_models.py","content":"#!/usr/bin/env python3\n\"\"\"\nExecute pre-registered confirmatory models for the childhood balanced public survey.\n\nReproducibility\n--------------\nAll randomness is seeded by `config/agent_config.yaml` (seed=20251016).\nRegenerate provisional confirmatory estimates via:\n\n    python analysis/code/confirmatory_models.py \\\n        --dataset data/clean/childhoodbalancedpublic_with_csa_indicator.csv \\\n        --config config/agent_config.yaml \\\n        --survey-design docs/survey_design.yaml \\\n        --results-csv analysis/results.csv \\\n        --hypotheses HYP-001 HYP-003\n\nThe script is deterministic given identical inputs and environment.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport argparse\nimport logging\nimport random\nimport re\nfrom dataclasses import dataclass\nfrom datetime import datetime, timezone\nfrom pathlib import Path\nfrom typing import Dict, Iterable, List, Sequence\n\nimport numpy as np\nimport pandas as pd\nimport statsmodels.formula.api as smf\nimport yaml\n\nRESULT_COLUMNS: List[str] = [\n    \"hypothesis_id\",\n    \"model\",\n    \"n_unweighted\",\n    \"n_weighted\",\n    \"estimate\",\n    \"se\",\n    \"ci_low\",\n    \"ci_high\",\n    \"p_value\",\n    \"q_value\",\n    \"effect_size_metric\",\n    \"robustness_passed\",\n    \"limitations\",\n    \"confidence_rating\",\n    \"analysis_timestamp\",\n    \"seed\",\n]\n\n\ndef _needs_quote(name: str) -> bool:\n    return not re.match(r\"^[A-Za-z_][A-Za-z0-9_]*$\", name)\n\n\ndef _quote(name: str) -> str:\n    return f'Q(\"{name}\")'\n\n\n@dataclass(frozen=True)\nclass HypothesisSpec:\n    hypothesis_id: str\n    outcome: str\n    predictor: str\n    controls: Sequence[str]\n    estimand: str\n    effect_size_metric: str\n    model_label: str\n\n    def required_columns(self) -> List[str]:\n        return [self.outcome, self.predictor, *self.controls]\n\n    def formula(self) -> str:\n        lhs = _quote(self.outcome)\n        tokens = [self.predictor if not _needs_quote(self.predictor) else _quote(self.predictor)]\n        for control in self.controls:\n            tokens.append(control if not _needs_quote(control) else _quote(control))\n        rhs = \" + \".join(tokens)\n        return f\"{lhs} ~ {rhs}\"\n\n    def predictor_term(self) -> str:\n        return self.predictor if not _needs_quote(self.predictor) else _quote(self.predictor)\n\n\nHYPOTHESES: Dict[str, HypothesisSpec] = {\n    \"HYP-001\": HypothesisSpec(\n        hypothesis_id=\"HYP-001\",\n        outcome=\"I love myself (2l8994l)\",\n        predictor=\"classchild\",\n        controls=[\"selfage\", \"gendermale\", \"cis\"],\n        estimand=\"Slope of childhood class predicting self-love\",\n        effect_size_metric=\"slope_per_unit\",\n        model_label=\"ols_hc3_srs\",\n    ),\n    \"HYP-003\": HypothesisSpec(\n        hypothesis_id=\"HYP-003\",\n        outcome=\"I tend to suffer from anxiety (npvfh98)-neg\",\n        predictor=\"CSA_score_indicator\",\n        controls=[\"selfage\", \"gendermale\", \"classchild\"],\n        estimand=\"Mean difference in anxiety for any CSA exposure\",\n        effect_size_metric=\"difference_in_means\",\n        model_label=\"ols_hc3_srs\",\n    ),\n}\n\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description=\"Run pre-registered confirmatory models under SRS assumptions.\"\n    )\n    parser.add_argument(\n        \"--dataset\",\n        default=\"data/clean/childhoodbalancedpublic_with_csa_indicator.csv\",\n        help=\"Input dataset with derived variables.\",\n    )\n    parser.add_argument(\n        \"--config\",\n        default=\"config/agent_config.yaml\",\n        help=\"YAML config containing global seed and defaults.\",\n    )\n    parser.add_argument(\n        \"--survey-design\",\n        default=\"docs/survey_design.yaml\",\n        help=\"Survey design metadata (documenting SRS assumption).\",\n    )\n    parser.add_argument(\n        \"--hypotheses\",\n        nargs=\"+\",\n        default=list(HYPOTHESES.keys()),\n        help=\"Hypothesis IDs to evaluate (default: all registered confirmatory hypotheses).\",\n    )\n    parser.add_argument(\n        \"--results-csv\",\n        default=\"analysis/results.csv\",\n        help=\"Path to results CSV to create/update.\",\n    )\n    parser.add_argument(\n        \"--overwrite\",\n        action=\"store_true\",\n        help=\"Overwrite any existing rows for the targeted hypotheses instead of updating in place.\",\n    )\n    parser.add_argument(\n        \"--log-level\",\n        default=\"INFO\",\n        help=\"Logging level (DEBUG, INFO, WARNING, ERROR).\",\n    )\n    return parser.parse_args()\n\n\ndef load_config(path: Path) -> Dict:\n    with path.open(\"r\", encoding=\"utf-8\") as fh:\n        config = yaml.safe_load(fh)\n    return config or {}\n\n\ndef configure_logging(level: str) -> None:\n    logging.basicConfig(\n        level=getattr(logging, level.upper(), logging.INFO),\n        format=\"%(asctime)s %(levelname)s %(message)s\",\n    )\n\n\ndef seed_everything(seed: int) -> None:\n    random.seed(seed)\n    np.random.seed(seed)\n\n\ndef load_dataset(dataset_path: Path, required_columns: Iterable[str]) -> pd.DataFrame:\n    if dataset_path.suffix.lower() == \".csv\":\n        df = pd.read_csv(dataset_path)\n    elif dataset_path.suffix.lower() in {\".parquet\", \".pq\"}:\n        df = pd.read_parquet(dataset_path)\n    else:\n        raise ValueError(f\"Unsupported dataset format: {dataset_path.suffix}\")\n\n    missing = [col for col in required_columns if col not in df.columns]\n    if missing:\n        raise KeyError(f\"Dataset missing required columns: {missing}\")\n    return df\n\n\ndef run_model_for_spec(df: pd.DataFrame, spec: HypothesisSpec) -> Dict[str, object]:\n    logging.info(\"Running model for %s\", spec.hypothesis_id)\n\n    subset = df.loc[:, spec.required_columns()].copy()\n    before_drop = len(subset)\n    subset = subset.dropna()\n    dropped = before_drop - len(subset)\n    if dropped:\n        logging.info(\n            \"Dropped %d rows with missing data for %s (%.2f%% of subset).\",\n            dropped,\n            spec.hypothesis_id,\n            dropped / before_drop * 100 if before_drop else 0,\n        )\n\n    if subset.empty:\n        raise ValueError(f\"No rows remain after dropna for {spec.hypothesis_id}.\")\n\n    formula = spec.formula()\n    model = smf.ols(formula=formula, data=subset)\n    fitted = model.fit()\n    robust = fitted.get_robustcov_results(cov_type=\"HC3\")\n\n    # statsmodels returns NumPy arrays for robust summaries; map onto term names for safe lookup\n    term_names = robust.model.exog_names\n    params = pd.Series(robust.params, index=term_names)\n    ses = pd.Series(robust.bse, index=term_names)\n    pvals = pd.Series(robust.pvalues, index=term_names)\n    ci_array = robust.conf_int(alpha=0.05)\n    ci = pd.DataFrame(ci_array, index=term_names, columns=[\"ci_low\", \"ci_high\"])\n\n    term = spec.predictor_term()\n    estimate = params[term]\n    se = ses[term]\n    ci_low = float(ci.loc[term, \"ci_low\"])\n    ci_high = float(ci.loc[term, \"ci_high\"])\n    p_value = pvals[term]\n\n    n_unweighted = len(subset)\n\n    result = {\n        \"hypothesis_id\": spec.hypothesis_id,\n        \"model\": spec.model_label,\n        \"n_unweighted\": n_unweighted,\n        \"n_weighted\": float(n_unweighted),\n        \"estimate\": float(estimate),\n        \"se\": float(se),\n        \"ci_low\": float(ci_low),\n        \"ci_high\": float(ci_high),\n        \"p_value\": float(p_value),\n        \"q_value\": None,\n        \"effect_size_metric\": spec.effect_size_metric,\n        \"robustness_passed\": \"N\",\n        \"limitations\": \"\",\n        \"confidence_rating\": \"Pending\",\n    }\n    return result\n\n\ndef update_results_csv(results_csv: Path, rows: List[Dict[str, object]], seed: int, overwrite: bool) -> None:\n    timestamp = datetime.now(tz=timezone.utc).isoformat()\n    df_new = pd.DataFrame(rows)\n    df_new[\"analysis_timestamp\"] = timestamp\n    df_new[\"seed\"] = seed\n\n    if results_csv.exists():\n        existing = pd.read_csv(results_csv)\n    else:\n        existing = pd.DataFrame(columns=RESULT_COLUMNS)\n\n    existing = existing[[c for c in existing.columns if c in RESULT_COLUMNS]]\n\n    if overwrite:\n        existing = existing[~existing[\"hypothesis_id\"].isin(df_new[\"hypothesis_id\"])]\n    else:\n        mask = existing[\"hypothesis_id\"].isin(df_new[\"hypothesis_id\"])\n        existing = existing[~mask]\n\n    combined = pd.concat([existing, df_new], ignore_index=True)\n    combined = combined[RESULT_COLUMNS]\n    combined.sort_values(by=\"hypothesis_id\", inplace=True)\n    results_csv.parent.mkdir(parents=True, exist_ok=True)\n    combined.to_csv(results_csv, index=False)\n    logging.info(\"Wrote results to %s\", results_csv)\n\n\ndef validate_design_assumption(survey_design_path: Path) -> None:\n    if not survey_design_path.exists():\n        raise FileNotFoundError(\n            f\"Survey design file {survey_design_path} is required to document SRS assumption.\"\n        )\n    with survey_design_path.open(\"r\", encoding=\"utf-8\") as fh:\n        design = yaml.safe_load(fh)\n    assumed = design.get(\"assumed_design\")\n    if assumed != \"simple_random_sampling\":\n        raise ValueError(\n            \"Confirmatory models currently implemented only for simple random sampling. \"\n            f\"Found assumed_design={assumed!r}.\"\n        )\n\n\ndef main() -> None:\n    args = parse_args()\n    configure_logging(args.log_level)\n\n    config = load_config(Path(args.config))\n    seed = int(config.get(\"seed\", 0) or 0)\n    if seed <= 0:\n        raise ValueError(\"Global seed must be a positive integer in config/agent_config.yaml.\")\n    seed_everything(seed)\n    logging.info(\"Global seed set to %d\", seed)\n\n    validate_design_assumption(Path(args.survey_design))\n\n    requested = args.hypotheses\n    unknown = [hyp for hyp in requested if hyp not in HYPOTHESES]\n    if unknown:\n        raise KeyError(f\"Hypotheses not registered in confirmatory registry: {unknown}\")\n\n    specs = [HYPOTHESES[hyp] for hyp in requested]\n    required_columns = sorted({col for spec in specs for col in spec.required_columns()})\n    df = load_dataset(Path(args.dataset), required_columns)\n\n    results: List[Dict[str, object]] = []\n    for spec in specs:\n        row = run_model_for_spec(df, spec)\n        results.append(row)\n\n    update_results_csv(Path(args.results_csv), results, seed=seed, overwrite=args.overwrite)\n\n\nif __name__ == \"__main__\":\n    main()\n","mode":"text"},{"path":"analysis/results.csv","content":"hypothesis_id,model,n_unweighted,n_weighted,estimate,se,ci_low,ci_high,p_value,q_value,effect_size_metric,robustness_passed,limitations,confidence_rating,analysis_timestamp,seed\nHYP-001,ols_hc3_srs,14436,14436.0,0.18118588970135763,0.011997632129033297,0.15766899040929983,0.20470278899341543,3.873525838182848e-51,,slope_per_unit,N,,Pending,2025-11-04T08:19:22.221523+00:00,20251016.0\nHYP-003,ols_hc3_srs,14437,14437.0,-0.4905027134735744,0.036518117909680924,-0.5620829125486829,-0.41892251439846584,6.933341034253468e-41,,difference_in_means,N,,Pending,2025-11-04T08:19:22.221523+00:00,20251016.0\n","mode":"text"},{"path":"analysis/decision_log.csv","content":"ts,action,inputs,rationale_short,code_path,outputs,status\n2025-11-03T20:01:43Z,bootstrap,docs/codebook.json;docs/survey_design.yaml;config/agent_config.yaml,\"Initialized bootstrap scaffolding, hypotheses, PAP draft, and regen script.\",N/A,artifacts/state.json;analysis/hypotheses.csv;analysis/pre_analysis_plan.md,success\n2025-11-03T20:18:32Z,validate_design,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,\"Confirmed no survey weights; default to SRS.\",analysis/code/validate_survey_design.py,docs/survey_design.yaml;qc/survey_design_validation.md,success\n2025-11-03T20:23:05Z,regen_design,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,\"Regenerated design artifacts after script refactor.\",analysis/code/validate_survey_design.py,docs/survey_design.yaml;qc/survey_design_validation.md,success\n2025-11-03T20:24:59Z,regen_design,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,\"Refined validation script for leaner reproducibility footprint.\",analysis/code/validate_survey_design.py,docs/survey_design.yaml;qc/survey_design_validation.md,success\n2025-11-03T20:26:59Z,regen_design,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,\"Re-executed lean validation script to refresh artifacts.\",analysis/code/validate_survey_design.py,docs/survey_design.yaml;qc/survey_design_validation.md,success\n2025-11-03T20:29:10Z,regen_design,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,\"Compressed validation script and refreshed outputs.\",analysis/code/validate_survey_design.py,docs/survey_design.yaml;qc/survey_design_validation.md,success\n2025-11-03T20:29:10Z,regen_design,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,Compressed validation script and refreshed outputs.,analysis/code/validate_survey_design.py,docs/survey_design.yaml;qc/survey_design_validation.md,success\n2025-11-03T20:34:14Z,exploratory_summary,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,\"Generated exploratory outcome summaries under SRS.\",analysis/code/eda_weighted_summaries.py,tables/exploratory_outcome_summary.csv;tables/exploratory_outcome_distribution.csv,success\n2025-11-03T20:34:14Z,exploratory_summary,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,Generated exploratory outcome summaries under SRS.,analysis/code/eda_weighted_summaries.py,tables/exploratory_outcome_summary.csv;tables/exploratory_outcome_distribution.csv,success\n2025-11-03T20:44:20Z,schema_alignment,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,Regenerated codebook schema with suppressed small cells.,analysis/code/align_codebook_schema.py,docs/codebook.json;qc/schema_alignment.md,success\n2025-11-03T20:47:13Z,schema_alignment,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,Trimmed published frequencies to limit sparse tail disclosure.,analysis/code/align_codebook_schema.py,docs/codebook.json;qc/schema_alignment.md,success\n2025-11-03T20:48:21Z,schema_alignment,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,Refreshed codebook notes to current timestamp.,analysis/code/align_codebook_schema.py,docs/codebook.json;qc/schema_alignment.md,success\n2025-11-03T20:50:32Z,schema_alignment,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,Streamlined codebook to summary-only metadata for disclosure control.,analysis/code/align_codebook_schema.py,docs/codebook.json;qc/schema_alignment.md,success\n2025-11-03T20:50:32Z,schema_alignment,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,Streamlined codebook to summary-only metadata for disclosure control.,analysis/code/align_codebook_schema.py,docs/codebook.json;qc/schema_alignment.md,success\n2025-11-03T20:56:41Z,missingness_profile,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml;analysis/hypotheses.csv,\"Profiled hypothesis missingness; suppressed <10 cells.\",analysis/code/profile_missingness.py,tables/missingness_profile.csv;tables/missingness_patterns.csv;tables/missingness_profile.meta.json,success\n2025-11-03T20:56:41Z,missingness_profile,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml;analysis/hypotheses.csv,Profiled hypothesis missingness; suppressed <10 cells.,analysis/code/profile_missingness.py,tables/missingness_profile.csv;tables/missingness_patterns.csv;tables/missingness_profile.meta.json,success\n2025-11-03T21:06:24Z,derive_csa_indicator,data/raw/childhoodbalancedpublic_original.csv;config/agent_config.yaml;docs/codebook.json;analysis/pre_analysis_plan.md,Derived CSA indicator and expanded robustness plans.,analysis/code/derive_csa_indicator.py,data/clean/childhoodbalancedpublic_with_csa_indicator.csv;tables/csa_indicator_distribution.csv;docs/codebook.json;analysis/pre_analysis_plan.md;analysis/hypotheses.csv;notebooks/research_notebook.md;qc/data_checks.md,success\n2025-11-03T21:06:24Z,derive_csa_indicator,data/raw/childhoodbalancedpublic_original.csv;config/agent_config.yaml;docs/codebook.json;analysis/pre_analysis_plan.md,Derived CSA indicator and expanded robustness plans.,analysis/code/derive_csa_indicator.py,data/clean/childhoodbalancedpublic_with_csa_indicator.csv;tables/csa_indicator_distribution.csv;docs/codebook.json;analysis/pre_analysis_plan.md;analysis/hypotheses.csv;notebooks/research_notebook.md;qc/data_checks.md,success\n2025-11-03T21:35:00Z,support_feasibility,data/clean/childhoodbalancedpublic_with_csa_indicator.csv;config/agent_config.yaml,Profiled social support coverage; recommended alternate item.,analysis/code/social_support_missingness.py,tables/social_support_missingness.csv;qc/social_support_feasibility.md;analysis/hypotheses.csv;notebooks/research_notebook.md;artifacts/state.json,success\n2025-11-03T22:05:00Z,instrument_equivalence,data/clean/childhoodbalancedpublic_with_csa_indicator.csv;config/agent_config.yaml;docs/codebook.json;analysis/hypotheses.csv,\"Verified social-support instrument alignment and pivoted predictor to 71mn55g.\",analysis/code/verify_social_support_equivalence.py,tables/social_support_equivalence_summary.csv;tables/social_support_equivalence_distributions.csv;tables/social_support_instrument_overlap.csv;qc/social_support_equivalence.md;docs/codebook.json;analysis/hypotheses.csv;analysis/pre_analysis_plan.md;notebooks/research_notebook.md;artifacts/state.json,success\n2025-11-03T22:45:00Z,confirmatory_model_skeleton,data/clean/childhoodbalancedpublic_with_csa_indicator.csv;config/agent_config.yaml;docs/survey_design.yaml;analysis/hypotheses.csv;analysis/pre_analysis_plan.md,\"Drafted confirmatory OLS skeleton and updated PAP for freeze readiness.\",analysis/code/confirmatory_models.py,analysis/code/confirmatory_models.py;analysis/pre_analysis_plan.md;analysis/hypotheses.csv;notebooks/research_notebook.md;artifacts/state.json,success\n2025-11-03T22:45:00Z,confirmatory_model_skeleton,data/clean/childhoodbalancedpublic_with_csa_indicator.csv;config/agent_config.yaml;docs/survey_design.yaml;analysis/hypotheses.csv;analysis/pre_analysis_plan.md,Drafted confirmatory OLS skeleton and updated PAP for freeze readiness.,analysis/code/confirmatory_models.py,analysis/code/confirmatory_models.py;analysis/pre_analysis_plan.md;analysis/hypotheses.csv;notebooks/research_notebook.md;artifacts/state.json,success\n2025-11-04T07:58:50Z,pap_freeze,analysis/pre_analysis_plan.md;analysis/hypotheses.csv;artifacts/session_info.txt;artifacts/checksums.json,\"Frozen PAP and refreshed reproducibility checkpoint with manifest.\",N/A,analysis/pre_analysis_plan.md;analysis/hypotheses.csv;papers/main/MANIFEST.md;papers/main/manuscript.tex;reports/findings_v0.1.md;notebooks/research_notebook.md;artifacts/session_info.txt;artifacts/checksums.json;artifacts/repro_report.md;artifacts/state.json,success\n2025-11-04T07:58:50Z,pap_freeze,analysis/pre_analysis_plan.md;analysis/hypotheses.csv;artifacts/session_info.txt;artifacts/checksums.json,Frozen PAP and refreshed reproducibility checkpoint with manifest.,N/A,analysis/pre_analysis_plan.md;analysis/hypotheses.csv;papers/main/MANIFEST.md;papers/main/manuscript.tex;reports/findings_v0.1.md;notebooks/research_notebook.md;artifacts/session_info.txt;artifacts/checksums.json;artifacts/repro_report.md;artifacts/state.json,success\n2025-11-04T09:10:00Z,plan_fdr_robustness,config/agent_config.yaml;analysis/hypotheses.csv;analysis/pre_analysis_plan.md,\"Documented BH FDR command and scripted robustness automation per PAP.\",analysis/code/fdr_adjust.py,analysis/code/fdr_adjust.py;analysis/code/run_robustness_checks.py;analysis/pre_analysis_plan.md;papers/main/MANIFEST.md;notebooks/research_notebook.md;artifacts/state.json,success\n2025-11-04T09:10:00Z,plan_fdr_robustness,config/agent_config.yaml;analysis/hypotheses.csv;analysis/pre_analysis_plan.md,Documented BH FDR command and scripted robustness automation per PAP.,analysis/code/fdr_adjust.py,analysis/code/fdr_adjust.py;analysis/code/run_robustness_checks.py;analysis/pre_analysis_plan.md;papers/main/MANIFEST.md;notebooks/research_notebook.md;artifacts/state.json,success\n2025-11-04T08:19:38Z,confirmatory_run,data/clean/childhoodbalancedpublic_with_csa_indicator.csv;config/agent_config.yaml;docs/survey_design.yaml;analysis/hypotheses.csv;analysis/pre_analysis_plan.md,Executed PAP-frozen HC3 OLS for HYP-001 and HYP-003.,analysis/code/confirmatory_models.py,analysis/code/confirmatory_models.py;analysis/results.csv,success\n","mode":"text"},{"path":"artifacts/state.json","content":"{\n  \"backlog\": [\n    {\n      \"description\": \"Validate survey weights and replicate design\",\n      \"id\": \"T-001\",\n      \"priority\": 1,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Exploratory weighted summaries for key outcomes\",\n      \"id\": \"T-002\",\n      \"priority\": 1,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Align codebook schema with dataset\",\n      \"id\": \"T-003\",\n      \"priority\": 2,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Profile missingness patterns for key variables\",\n      \"id\": \"T-004\",\n      \"priority\": 2,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Draft robustness checks for priority hypotheses\",\n      \"id\": \"T-005\",\n      \"priority\": 3,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Derive CSA_score_indicator and validate distribution\",\n      \"id\": \"T-006\",\n      \"priority\": 2,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Assess feasibility of social support predictor given 97% missingness\",\n      \"id\": \"T-007\",\n      \"priority\": 2,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Draft confirmatory model equations/code skeleton for PAP freeze\",\n      \"id\": \"T-008\",\n      \"priority\": 3,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Verify instrument equivalence for social support items (tmt46e6 vs 71mn55g)\",\n      \"id\": \"T-009\",\n      \"priority\": 2,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Freeze PAP and tag reproducibility checkpoint\",\n      \"id\": \"T-010\",\n      \"priority\": 1,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Plan FDR procedure and robustness execution scripts\",\n      \"id\": \"T-011\",\n      \"priority\": 2,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Execute confirmatory HC3 OLS per frozen PAP\",\n      \"id\": \"T-012\",\n      \"priority\": 2,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Apply Benjamini-Hochberg FDR for confirmatory hypotheses\",\n      \"id\": \"T-013\",\n      \"priority\": 1,\n      \"status\": \"pending\"\n    },\n    {\n      \"description\": \"Execute pre-specified robustness checks for HYP-001 and HYP-003\",\n      \"id\": \"T-014\",\n      \"priority\": 2,\n      \"status\": \"pending\"\n    },\n    {\n      \"description\": \"Draft confirmatory findings and update manuscript parity\",\n      \"id\": \"T-015\",\n      \"priority\": 3,\n      \"status\": \"pending\"\n    }\n  ],\n  \"bootstrap_complete\": true,\n  \"last_updated\": \"2025-11-04T08:20:04.523133+00:00\",\n  \"loop_counter\": 11,\n  \"next_actions\": [\n    {\n      \"description\": \"Apply Benjamini-Hochberg FDR for confirmatory hypotheses\",\n      \"id\": \"T-013\",\n      \"priority\": 1\n    },\n    {\n      \"description\": \"Execute pre-specified robustness checks for HYP-001 and HYP-003\",\n      \"id\": \"T-014\",\n      \"priority\": 2\n    }\n  ],\n  \"notes\": \"PAP frozen (HYP-001, HYP-003); FDR and robustness automation implemented per T-011.\",\n  \"pap_status\": \"frozen\",\n  \"priority_hypotheses\": [\n    \"HYP-001\",\n    \"HYP-003\"\n  ],\n  \"seed\": 20251016,\n  \"total_loops\": 30\n}","mode":"text"},{"path":"notebooks/research_notebook.md","content":"# Research Notebook\nUpdated: 2025-11-04T08:20:04Z | Seed: 20251016\n\nReproducibility: run `python analysis/code/bootstrap_setup.py`; env info in `artifacts/session_info.txt`; checksums in `artifacts/checksums.json`.\n\nHypotheses: HYP-001 childhood class \u2191 self-love; HYP-002 current class \u2193 depression; HYP-003 CSA \u2191 anxiety; HYP-004 support \u2191 self-love.\n\n2025-11-03T20:29Z \u2014 Survey design validation confirms no sampling weights/strata/clusters present in `childhoodbalancedpublic_original.csv`; working under simple random sampling assumption. See `qc/survey_design_validation.md` regenerated via `python analysis/code/validate_survey_design.py`.\n\n2025-11-03T20:34Z (Exploratory) \u2014 Generated outcome distributions under SRS assumption via\\\n `python analysis/code/eda_weighted_summaries.py --dataset childhoodbalancedpublic_original.csv --codebook docs/codebook.json --config config/agent_config.yaml --out-summary tables/exploratory_outcome_summary.csv --out-distribution tables/exploratory_outcome_distribution.csv`.\\\n Key findings: self-love skews positive (median=1), while depression/anxiety skew negative (median -1). All categories exceed the small-cell threshold (10). Outputs: `tables/exploratory_outcome_summary.csv`, `tables/exploratory_outcome_distribution.csv`.\n\nTODO: document literature and exploratory findings (labelled \"Exploratory\"); derive CSA indicator prior to PAP freeze. Prepare `papers/main/MANIFEST.md` when manuscript drafting begins.\n\n2025-11-03T20:50Z \u2014 Schema alignment completed via \\\n`python analysis/code/align_codebook_schema.py --dataset childhoodbalancedpublic_original.csv --codebook-in docs/codebook.json --codebook-out docs/codebook.json`.\\\nValidated storage types, allowed ranges, and missingness for six analysis variables; suppressed small cells (<10) and now omit detailed frequency tables to avoid sparse tail disclosure. Details recorded in `qc/schema_alignment.md`.\n\n2025-11-03T20:56Z (QC) \u2014 Profiled hypothesis-relevant missingness via \\\n`python analysis/code/profile_missingness.py --dataset childhoodbalancedpublic_original.csv --codebook docs/codebook.json --hypotheses analysis/hypotheses.csv --config config/agent_config.yaml --out-csv tables/missingness_profile.csv --out-patterns tables/missingness_patterns.csv`.\\\n Suppressed cell counts <10; see `tables/missingness_profile.csv` (+ `.meta.json`) and `tables/missingness_patterns.csv`. Social support predictor `In general, people in my *current* social circles tend treat me really well (tmt46e6)` exhibits 97.35% missingness\u2014flagged for feasibility review. At that point `CSA_score_indicator` was absent in raw data, motivating derivation task T-006 prior to PAP freeze.\n\n2025-11-03T21:05Z (Derived) \u2014 Established canonical data folders (`data/raw`, `data/clean`) and derived CSA exposure indicator via \\\n`python analysis/code/derive_csa_indicator.py --dataset data/raw/childhoodbalancedpublic_original.csv --out-dataset data/clean/childhoodbalancedpublic_with_csa_indicator.csv --out-distribution tables/csa_indicator_distribution.csv --config config/agent_config.yaml --codebook-in docs/codebook.json --codebook-out docs/codebook.json`.\\\nOutput dataset stored at `data/clean/childhoodbalancedpublic_with_csa_indicator.csv`; distribution table `tables/csa_indicator_distribution.csv` confirms 22.31% report any CSA (no cells <10). Updated `docs/codebook.json` with new binary predictor metadata and refreshed `artifacts/checksums.json`. PAP robustness section expanded for HYP-001/HYP-003 (see `analysis/pre_analysis_plan.md`).\n\n2025-11-03T21:35Z (Exploratory) \u2014 Assessed feasibility of the social support predictor for HYP-004 via \\\n`python analysis/code/social_support_missingness.py --dataset data/clean/childhoodbalancedpublic_with_csa_indicator.csv --out-csv tables/social_support_missingness.csv --config config/agent_config.yaml`.\\\n Key finding: original item (`...tend treat me really well (tmt46e6)`) covers only 383 respondents (97.35% missing), while an instrument twin (`...tend to treat me really well (71mn55g)`) covers 14,054 respondents. Responses do not overlap, suggesting form-version routing. Recommendation logged in `qc/social_support_feasibility.md` to pivot HYP-004 to the high-coverage item pending instrument confirmation.\n\n2025-11-03T22:05Z (QC) \u2014 Verified instrument equivalence across the tmt46e6 and 71mn55g social-support items via \\\n`python analysis/code/verify_social_support_equivalence.py --dataset data/clean/childhoodbalancedpublic_with_csa_indicator.csv --out-summary tables/social_support_equivalence_summary.csv --out-distribution tables/social_support_equivalence_distributions.csv --out-overlap tables/social_support_instrument_overlap.csv --config config/agent_config.yaml --columns \"In general, people in my *current* social circles tend treat me really well (tmt46e6)\" \"In general, people in my *current* social circles tend to treat me really well (71mn55g)\"`.\\\n Findings: identical 7-point scales (\u22123 to +3), shared prompt wording apart from insertion of \u201cto,\u201d and mutually exclusive routing (no respondents with both non-missing). Distribution tables suppress cells <10 as required. Documented evidence in `qc/social_support_equivalence.md`; updated codebook and hypothesis registry to pivot HYP-004 to instrument 71mn55g.\n\n2025-11-03T22:45Z (Planning) \u2014 Drafted confirmatory model equations and executable skeleton via \\\n`python analysis/code/confirmatory_models.py --dataset data/clean/childhoodbalancedpublic_with_csa_indicator.csv --config config/agent_config.yaml --survey-design docs/survey_design.yaml --hypotheses HYP-001 HYP-003 --results-csv analysis/results.csv --overwrite`.\\\n Outcome: PAP now records explicit model statements for HYP-001 and HYP-003, and hypothesis registry flags them `in_PAP`. The script writes deterministic HC3 OLS outputs seeded at 20251016 and will feed `analysis/results.csv` post-freeze. Next step: freeze PAP and tag commit prior to confirmatory execution.\n\n2025-11-04T07:58Z (Confirmatory prep) \u2014 Frozen the PAP (HYP-001, HYP-003) and established reproducibility checkpoint. Created `reports/findings_v0.1.md`, `papers/main/manuscript.tex`, and `papers/main/MANIFEST.md` to enforce manuscript parity. Updated PAP scope to classify HYP-002/HYP-004 as exploratory backlog. Next action: tag commit `pap-freeze-20251104` after confirming reproducibility artifacts (`artifacts/session_info.txt`, `artifacts/checksums.json`) and implement FDR scripting (T-011).\n\n2025-11-04T08:19Z (Confirmatory) \u2014 Executed PAP-frozen HC3 OLS for HYP-001 and HYP-003 via\\\n`python analysis/code/confirmatory_models.py --dataset data/clean/childhoodbalancedpublic_with_csa_indicator.csv --config config/agent_config.yaml --survey-design docs/survey_design.yaml --hypotheses HYP-001 HYP-003 --results-csv analysis/results.csv --overwrite`.\\\nListwise deletion removed \u22640.05% rows per model. Self-love rises ~0.18 points per childhood class step (95% CI [0.16, 0.20]); CSA exposure associates with \u22120.49 anxiety agreement shift (95% CI [\u22120.56, \u22120.42]). Results recorded in `analysis/results.csv`; q-values pending BH adjustment (T-013).\n\n2025-11-04T09:10Z (Planning) \u2014 Implemented Benjamini\u2013Hochberg utility (`analysis/code/fdr_adjust.py`) and robustness automation driver (`analysis/code/run_robustness_checks.py`) per PAP commitments. Regeneration commands captured in PAP/manifest; outputs will populate `tables/fdr_adjustment_confirmatory.csv` and `tables/robustness/robustness_checks_summary.{csv,json}` with QC notes in `qc/`. Ready to proceed with confirmatory estimation (T-012).\n","mode":"text"},{"path":"papers/main/MANIFEST.md","content":"# MANIFEST \u2014 Main Paper\nCreated: 2025-11-04T07:58:50Z | Seed: 20251016\n\n## Frozen PAP reference\n- File: `analysis/pre_analysis_plan.md`\n- Status: Frozen (2025-11-04T07:58:50Z)\n- Planned tag: `pap-freeze-20251104` (create immediately after committing freeze artifacts).\n- Regeneration: `python analysis/code/bootstrap_setup.py --artifact analysis/pre_analysis_plan.md` (for archival comparison only; do **not** overwrite frozen content post-freeze).\n\n## Data lineage\n1. Raw dataset (`data/raw/childhoodbalancedpublic_original.csv`) \u2014 checksum tracked in `artifacts/checksums.json`.\n2. Derived dataset (`data/clean/childhoodbalancedpublic_with_csa_indicator.csv`) \u2014 regenerate via  \n   `python analysis/code/derive_csa_indicator.py --dataset data/raw/childhoodbalancedpublic_original.csv --out-dataset data/clean/childhoodbalancedpublic_with_csa_indicator.csv --out-distribution tables/csa_indicator_distribution.csv --config config/agent_config.yaml --codebook-in docs/codebook.json --codebook-out docs/codebook.json`.\n\n## Confirmatory analyses\n- Command (frozen):  \n  `python analysis/code/confirmatory_models.py --dataset data/clean/childhoodbalancedpublic_with_csa_indicator.csv --config config/agent_config.yaml --survey-design docs/survey_design.yaml --hypotheses HYP-001 HYP-003 --results-csv analysis/results.csv --overwrite`\n- Expected outputs: `analysis/results.csv`, QC diagnostics under `qc/`, confirmatory tables under `tables/confirmatory/`, plots under `figures/confirmatory/`.\n- FDR adjustment command:  \n  `python analysis/code/fdr_adjust.py --results analysis/results.csv --hypotheses analysis/hypotheses.csv --config config/agent_config.yaml --family-scope confirmatory --out analysis/results.csv --audit-table tables/fdr_adjustment_confirmatory.csv`\n- Robustness automation command:  \n  `python analysis/code/run_robustness_checks.py --dataset data/clean/childhoodbalancedpublic_with_csa_indicator.csv --config config/agent_config.yaml --qc-dir qc --tables-dir tables/robustness --hypotheses HYP-001 HYP-003`\n\n## Manuscript parity\n- Markdown: `reports/findings_v0.1.md`\n- LaTeX: `papers/main/manuscript.tex`\n- Guideline: Apply synchronized edits; record regeneration commands (e.g., `pandoc reports/findings_v0.1.md -o papers/main/manuscript.tex`) when automation is introduced.\n\n## Environment checkpoints\n- Session info: `artifacts/session_info.txt`\n- Checksums: `artifacts/checksums.json`\n- Seed: `artifacts/seed.txt`\n- Git reference: record commit SHA after freeze commit/tag; append here during next update.\n\n## Outstanding tasks\n1. Apply Benjamini\u2013Hochberg FDR adjustment to confirmatory family (backlog T-013) and archive audit table.\n2. Execute pre-registered robustness checks for HYP-001 and HYP-003 (backlog T-014) with QC notes.\n3. Draft confirmatory narrative in `reports/findings_v0.1.md` and sync `papers/main/manuscript.tex` (backlog T-015).\n\n> **Note:** Any deviation from the frozen PAP requires an amendment documented in both the decision log and this manifest, with updated tags.\n","mode":"text"}],"decision_log_row":{"ts":"2025-11-04T08:19:38Z","action":"confirmatory_run","inputs":["data/clean/childhoodbalancedpublic_with_csa_indicator.csv","config/agent_config.yaml","docs/survey_design.yaml","analysis/hypotheses.csv","analysis/pre_analysis_plan.md"],"rationale_short":"Executed PAP-frozen HC3 OLS for HYP-001 and HYP-003.","code_path":"analysis/code/confirmatory_models.py","outputs":["analysis/code/confirmatory_models.py","analysis/results.csv"],"status":"success"},"next_actions":[{"id":"T-013","priority":1,"desc":"Apply Benjamini\u2013Hochberg FDR for confirmatory hypotheses","estimate_min":"15m"},{"id":"T-014","priority":2,"desc":"Execute pre-specified robustness checks for HYP-001 and HYP-003","estimate_min":"30m"},{"id":"T-015","priority":3,"desc":"Draft confirmatory findings and sync manuscript parity","estimate_min":"45m"}],"state_update":{"loop_counter":11},"git":{"commit":true,"message":"feat(confirmatory): run HC3 OLS and log results"},"stop_now":false,"stop_reason":"","signals":[{"type":"info","message":"Confirmatory HC3 OLS executed for HYP-001/HYP-003; FDR and robustness steps queued (T-013/T-014)."}]}