{
  "files": [
    {
      "path": "analysis/code/confirmatory_models.py",
      "content": "#!/usr/bin/env python3\n\"\"\"\nExecute pre-registered confirmatory models for the childhood balanced public survey.\n\nReproducibility\n--------------\nAll randomness is seeded by `config/agent_config.yaml` (seed=20251016).\nRegenerate provisional confirmatory estimates via:\n\n    python analysis/code/confirmatory_models.py \\\n        --dataset data/clean/childhoodbalancedpublic_with_csa_indicator.csv \\\n        --config config/agent_config.yaml \\\n        --survey-design docs/survey_design.yaml \\\n        --results-csv analysis/results.csv \\\n        --hypotheses HYP-001 HYP-003\n\nThe script is deterministic given identical inputs and environment.\n\"\"\"\n\nfrom __future__ import annotations\n\nimport argparse\nimport logging\nimport random\nimport re\nfrom dataclasses import dataclass\nfrom datetime import datetime, timezone\nfrom pathlib import Path\nfrom typing import Dict, Iterable, List, Sequence\n\nimport numpy as np\nimport pandas as pd\nimport statsmodels.formula.api as smf\nimport yaml\n\nRESULT_COLUMNS: List[str] = [\n    \"hypothesis_id\",\n    \"model\",\n    \"n_unweighted\",\n    \"n_weighted\",\n    \"estimate\",\n    \"se\",\n    \"ci_low\",\n    \"ci_high\",\n    \"p_value\",\n    \"q_value\",\n    \"effect_size_metric\",\n    \"robustness_passed\",\n    \"limitations\",\n    \"confidence_rating\",\n    \"analysis_timestamp\",\n    \"seed\",\n]\n\n\ndef _needs_quote(name: str) -> bool:\n    return not re.match(r\"^[A-Za-z_][A-Za-z0-9_]*$\", name)\n\n\ndef _quote(name: str) -> str:\n    return f'Q(\"{name}\")'\n\n\n@dataclass(frozen=True)\nclass HypothesisSpec:\n    hypothesis_id: str\n    outcome: str\n    predictor: str\n    controls: Sequence[str]\n    estimand: str\n    effect_size_metric: str\n    model_label: str\n\n    def required_columns(self) -> List[str]:\n        return [self.outcome, self.predictor, *self.controls]\n\n    def formula(self) -> str:\n        lhs = _quote(self.outcome)\n        tokens = [self.predictor if not _needs_quote(self.predictor) else _quote(self.predictor)]\n        for control in self.controls:\n            tokens.append(control if not _needs_quote(control) else _quote(control))\n        rhs = \" + \".join(tokens)\n        return f\"{lhs} ~ {rhs}\"\n\n    def predictor_term(self) -> str:\n        return self.predictor if not _needs_quote(self.predictor) else _quote(self.predictor)\n\n\nHYPOTHESES: Dict[str, HypothesisSpec] = {\n    \"HYP-001\": HypothesisSpec(\n        hypothesis_id=\"HYP-001\",\n        outcome=\"I love myself (2l8994l)\",\n        predictor=\"classchild\",\n        controls=[\"selfage\", \"gendermale\", \"cis\"],\n        estimand=\"Slope of childhood class predicting self-love\",\n        effect_size_metric=\"slope_per_unit\",\n        model_label=\"ols_hc3_srs\",\n    ),\n    \"HYP-003\": HypothesisSpec(\n        hypothesis_id=\"HYP-003\",\n        outcome=\"I tend to suffer from anxiety (npvfh98)-neg\",\n        predictor=\"CSA_score_indicator\",\n        controls=[\"selfage\", \"gendermale\", \"classchild\"],\n        estimand=\"Mean difference in anxiety for any CSA exposure\",\n        effect_size_metric=\"difference_in_means\",\n        model_label=\"ols_hc3_srs\",\n    ),\n}\n\n\ndef parse_args() -> argparse.Namespace:\n    parser = argparse.ArgumentParser(\n        description=\"Run pre-registered confirmatory models under SRS assumptions.\"\n    )\n    parser.add_argument(\n        \"--dataset\",\n        default=\"data/clean/childhoodbalancedpublic_with_csa_indicator.csv\",\n        help=\"Input dataset with derived variables.\",\n    )\n    parser.add_argument(\n        \"--config\",\n        default=\"config/agent_config.yaml\",\n        help=\"YAML config containing global seed and defaults.\",\n    )\n    parser.add_argument(\n        \"--survey-design\",\n        default=\"docs/survey_design.yaml\",\n        help=\"Survey design metadata (documenting SRS assumption).\",\n    )\n    parser.add_argument(\n        \"--hypotheses\",\n        nargs=\"+\",\n        default=list(HYPOTHESES.keys()),\n        help=\"Hypothesis IDs to evaluate (default: all registered confirmatory hypotheses).\",\n    )\n    parser.add_argument(\n        \"--results-csv\",\n        default=\"analysis/results.csv\",\n        help=\"Path to results CSV to create/update.\",\n    )\n    parser.add_argument(\n        \"--overwrite\",\n        action=\"store_true\",\n        help=\"Overwrite any existing rows for the targeted hypotheses instead of updating in place.\",\n    )\n    parser.add_argument(\n        \"--log-level\",\n        default=\"INFO\",\n        help=\"Logging level (DEBUG, INFO, WARNING, ERROR).\",\n    )\n    return parser.parse_args()\n\n\ndef load_config(path: Path) -> Dict:\n    with path.open(\"r\", encoding=\"utf-8\") as fh:\n        config = yaml.safe_load(fh)\n    return config or {}\n\n\ndef configure_logging(level: str) -> None:\n    logging.basicConfig(\n        level=getattr(logging, level.upper(), logging.INFO),\n        format=\"%(asctime)s %(levelname)s %(message)s\",\n    )\n\n\ndef seed_everything(seed: int) -> None:\n    random.seed(seed)\n    np.random.seed(seed)\n\n\ndef load_dataset(dataset_path: Path, required_columns: Iterable[str]) -> pd.DataFrame:\n    if dataset_path.suffix.lower() == \".csv\":\n        df = pd.read_csv(dataset_path)\n    elif dataset_path.suffix.lower() in {\".parquet\", \".pq\"}:\n        df = pd.read_parquet(dataset_path)\n    else:\n        raise ValueError(f\"Unsupported dataset format: {dataset_path.suffix}\")\n\n    missing = [col for col in required_columns if col not in df.columns]\n    if missing:\n        raise KeyError(f\"Dataset missing required columns: {missing}\")\n    return df\n\n\ndef run_model_for_spec(df: pd.DataFrame, spec: HypothesisSpec) -> Dict[str, object]:\n    logging.info(\"Running model for %s\", spec.hypothesis_id)\n\n    subset = df.loc[:, spec.required_columns()].copy()\n    before_drop = len(subset)\n    subset = subset.dropna()\n    dropped = before_drop - len(subset)\n    if dropped:\n        logging.info(\n            \"Dropped %d rows with missing data for %s (%.2f%% of subset).\",\n            dropped,\n            spec.hypothesis_id,\n            dropped / before_drop * 100 if before_drop else 0,\n        )\n\n    if subset.empty:\n        raise ValueError(f\"No rows remain after dropna for {spec.hypothesis_id}.\")\n\n    formula = spec.formula()\n    model = smf.ols(formula=formula, data=subset)\n    fitted = model.fit()\n    robust = fitted.get_robustcov_results(cov_type=\"HC3\")\n\n    term = spec.predictor_term()\n    estimate = robust.params[term]\n    se = robust.bse[term]\n    ci_low, ci_high = robust.conf_int(alpha=0.05).loc[term]\n    p_value = robust.pvalues[term]\n\n    n_unweighted = len(subset)\n\n    result = {\n        \"hypothesis_id\": spec.hypothesis_id,\n        \"model\": spec.model_label,\n        \"n_unweighted\": n_unweighted,\n        \"n_weighted\": float(n_unweighted),\n        \"estimate\": float(estimate),\n        \"se\": float(se),\n        \"ci_low\": float(ci_low),\n        \"ci_high\": float(ci_high),\n        \"p_value\": float(p_value),\n        \"q_value\": None,\n        \"effect_size_metric\": spec.effect_size_metric,\n        \"robustness_passed\": \"N\",\n        \"limitations\": \"\",\n        \"confidence_rating\": \"Pending\",\n    }\n    return result\n\n\ndef update_results_csv(results_csv: Path, rows: List[Dict[str, object]], seed: int, overwrite: bool) -> None:\n    timestamp = datetime.now(tz=timezone.utc).isoformat()\n    df_new = pd.DataFrame(rows)\n    df_new[\"analysis_timestamp\"] = timestamp\n    df_new[\"seed\"] = seed\n\n    if results_csv.exists():\n        existing = pd.read_csv(results_csv)\n    else:\n        existing = pd.DataFrame(columns=RESULT_COLUMNS)\n\n    existing = existing[[c for c in existing.columns if c in RESULT_COLUMNS]]\n\n    if overwrite:\n        existing = existing[~existing[\"hypothesis_id\"].isin(df_new[\"hypothesis_id\"])]\n    else:\n        mask = existing[\"hypothesis_id\"].isin(df_new[\"hypothesis_id\"])\n        existing = existing[~mask]\n\n    combined = pd.concat([existing, df_new], ignore_index=True)\n    combined = combined[RESULT_COLUMNS]\n    combined.sort_values(by=\"hypothesis_id\", inplace=True)\n    results_csv.parent.mkdir(parents=True, exist_ok=True)\n    combined.to_csv(results_csv, index=False)\n    logging.info(\"Wrote results to %s\", results_csv)\n\n\ndef validate_design_assumption(survey_design_path: Path) -> None:\n    if not survey_design_path.exists():\n        raise FileNotFoundError(\n            f\"Survey design file {survey_design_path} is required to document SRS assumption.\"\n        )\n    with survey_design_path.open(\"r\", encoding=\"utf-8\") as fh:\n        design = yaml.safe_load(fh)\n    assumed = design.get(\"assumed_design\")\n    if assumed != \"simple_random_sampling\":\n        raise ValueError(\n            \"Confirmatory models currently implemented only for simple random sampling. \"\n            f\"Found assumed_design={assumed!r}.\"\n        )\n\n\ndef main() -> None:\n    args = parse_args()\n    configure_logging(args.log_level)\n\n    config = load_config(Path(args.config))\n    seed = int(config.get(\"seed\", 0) or 0)\n    if seed <= 0:\n        raise ValueError(\"Global seed must be a positive integer in config/agent_config.yaml.\")\n    seed_everything(seed)\n    logging.info(\"Global seed set to %d\", seed)\n\n    validate_design_assumption(Path(args.survey_design))\n\n    requested = args.hypotheses\n    unknown = [hyp for hyp in requested if hyp not in HYPOTHESES]\n    if unknown:\n        raise KeyError(f\"Hypotheses not registered in confirmatory registry: {unknown}\")\n\n    specs = [HYPOTHESES[hyp] for hyp in requested]\n    required_columns = sorted({col for spec in specs for col in spec.required_columns()})\n    df = load_dataset(Path(args.dataset), required_columns)\n\n    results: List[Dict[str, object]] = []\n    for spec in specs:\n        row = run_model_for_spec(df, spec)\n        results.append(row)\n\n    update_results_csv(Path(args.results_csv), results, seed=seed, overwrite=args.overwrite)\n\n\nif __name__ == \"__main__\":\n    main()\n",
      "mode": "text"
    },
    {
      "path": "analysis/pre_analysis_plan.md",
      "content": "# PAP Draft\nGenerated: 2025-11-03T22:05:00Z | Seed: 20251016\nStatus: Draft (not frozen) | Regen: `python analysis/code/bootstrap_setup.py --artifact analysis/pre_analysis_plan.md`\n\nData inputs:\n- Raw: `data/raw/childhoodbalancedpublic_original.csv`\n- Clean (derived): `data/clean/childhoodbalancedpublic_with_csa_indicator.csv` via `python analysis/code/derive_csa_indicator.py --dataset data/raw/childhoodbalancedpublic_original.csv --out-dataset data/clean/childhoodbalancedpublic_with_csa_indicator.csv --out-distribution tables/csa_indicator_distribution.csv --config config/agent_config.yaml --codebook-in docs/codebook.json --codebook-out docs/codebook.json`\n\nPortfolio: HYP-001 (High), HYP-002 (Medium), HYP-003 (High), HYP-004 (Medium)\n\n## HYP-001 \u2014 Childhood class and adult self-love\n- **Outcome**: `I love myself (2l8994l)` (Likert \u22123 to +3)  \n  **Predictor**: `classchild` (0\u20136 ordinal)  \n  **Covariates**: `selfage`, `gendermale`, `cis`\n- **Estimand**: Average change in outcome per one-step increase in childhood class (design-based OLS with HC3).\n- **Primary model**: `survey`-adjusted linear regression under SRS assumption (weights=1). Robust HC3 standard errors with seed 20251016.\n- **Model equation** (confirmatory, SRS):  \n  `y_i = \u03b2_0 + \u03b2_1 \u00b7 classchild_i + \u03b2_2 \u00b7 selfage_i + \u03b2_3 \u00b7 gendermale_i + \u03b2_4 \u00b7 cis_i + \u03b5_i`, with HC3 variance.  \n  `\u03b2_1` identifies the estimand.\n- **Analysis code**: `python analysis/code/confirmatory_models.py --dataset data/clean/childhoodbalancedpublic_with_csa_indicator.csv --config config/agent_config.yaml --survey-design docs/survey_design.yaml --hypotheses HYP-001 --results-csv analysis/results.csv --overwrite`\n- **Robustness checks**:  \n  1. Treat `classchild` as categorical with Helmert contrasts (tests functional form).  \n  2. Fit proportional-odds ordinal logit on the outcome; assess Brant test to flag violations.  \n  3. Standardise outcome to z-score and refit OLS to confirm scale invariance.\n- **Missing-data plan**: If any covariate missingness >5%, execute multiple imputation (m=5, deterministic seed 20251016) before confirmatory analysis; otherwise listwise deletion.\n\n## HYP-003 \u2014 CSA exposure and anxiety agreement\n- **Outcome**: `I tend to suffer from anxiety (npvfh98)-neg`\n- **Predictor**: `CSA_score_indicator` (derived binary; 1 if CSA_score>0)\n- **Covariates**: `selfage`, `gendermale`, `classchild`\n- **Estimand**: Difference in mean anxiety agreement between any CSA exposure vs none.\n- **Primary model**: OLS with HC3 under SRS, plus design-based two-sample comparison (Welch t using survey variance) to confirm direction/scale.\n- **Model equation** (confirmatory, SRS):  \n  `y_i = \u03b2_0 + \u03b2_1 \u00b7 CSA_i + \u03b2_2 \u00b7 selfage_i + \u03b2_3 \u00b7 gendermale_i + \u03b2_4 \u00b7 classchild_i + \u03b5_i`, HC3 variance; `\u03b2_1` captures the mean difference between exposed vs non-exposed.\n- **Analysis code**: `python analysis/code/confirmatory_models.py --dataset data/clean/childhoodbalancedpublic_with_csa_indicator.csv --config config/agent_config.yaml --survey-design docs/survey_design.yaml --hypotheses HYP-003 --results-csv analysis/results.csv --overwrite`\n- **Robustness checks**:  \n  1. Logistic regression on `CSA_score_indicator` predicting high anxiety (>=1) to examine non-linear probability scale.  \n  2. Replace binary predictor with ordinal bins `{0, 1-3, 4+}` and test linear trend.  \n  3. Exclude extreme tail (`CSA_score` > 15) to assess leverage sensitivity.\n- **Missing-data plan**: Monitor derived indicator (currently 0% missing). If downstream models require additional variables with >5% missingness, extend MI plan above; record seeds.\n\n## HYP-004 \u2014 Social support and self-love (Proposed)\n- **Outcome**: `I love myself (2l8994l)`\n- **Predictor**: `In general, people in my *current* social circles tend to treat me really well (71mn55g)` (Likert \u22123 to +3; instrument equivalence verified against tmt46e6 via `analysis/code/verify_social_support_equivalence.py`).\n- **Covariates**: `selfage`, `gendermale`\n- **Rationale**: Pivot from low-coverage variant (`tmt46e6`, 2.65% coverage) to `71mn55g` (97.3%) after confirming identical wording/scale apart from routing typo. Instrument overlap check confirms mutually exclusive routing with no dual responders.\n- **Estimand**: Weighted change in self-love per one-unit increase in perceived support.\n- **Planned model**: Design-based OLS (HC3) treating the predictor as continuous; evaluate proportional-odds model if outcome retains ordinal interpretation.\n- **Robustness checks (pre-registration pending)**:  \n  1. Recode support predictor to three bins `{\u22640, 1-2, 3}` to assess non-linearity.  \n  2. Indicator for top-two responses (2/3) vs others to check threshold effects.\n- **Next steps**: Finalise model equation language and confirm inclusion/exclusion criteria before PAP freeze; update manuscript and hypothesis registry accordingly.\n\nRoadmap: 1) Finalize survey design assumptions and document SRS rationale. 2) Label exploratory descriptives (clearly marked). 3) Freeze PAP after verifying confirmatory code paths and tag git. 4) Execute confirmatory models per `analysis/code/confirmatory_models.py`, log seeds to `analysis/results.csv`, and mirror updates in `papers/main/MANIFEST.md`.\n\nManuscript parity: update `reports/findings_v0.1.md` and `papers/main/manuscript.tex` in lockstep; record regeneration commands alongside outputs.\n",
      "mode": "text"
    },
    {
      "path": "analysis/hypotheses.csv",
      "content": "id,family,description,outcome_var,predictors,controls,population/subset,estimand,status,notes\nHYP-001,Wellbeing,\"Childhood class positively relates to adult self-love.\",I love myself (2l8994l),classchild,\"selfage; gendermale; cis\",\"Non-missing classchild & outcome\",\"Weighted mean change per class unit\",in_PAP,\"Primary model: survey OLS (HC3). Robustness: (1) treat classchild as categorical with Helmert contrasts; (2) ordinal logit with proportional odds check; (3) re-center outcome to z-score for scale sensitivity. Confirmatory code: analysis/code/confirmatory_models.py (SRS).\"\nHYP-002,MentalHealth,\"Current class inversely relates to depression agreement.\",I tend to suffer from depression (wz901dj),classcurrent,\"selfage; gendermale; cis\",\"Non-missing classcurrent & outcome\",\"Weighted coefficient on classcurrent\",proposed,\"Spline robustness.\"\nHYP-003,MentalHealth,\"CSA exposure associates with higher anxiety agreement.\",I tend to suffer from anxiety (npvfh98)-neg,CSA_score_indicator,\"selfage; gendermale; classchild\",\"Observed CSA_score\",\"Weighted mean difference (CSA>0 vs 0)\",in_PAP,\"CSA_score_indicator derived via analysis/code/derive_csa_indicator.py (CSA_score>0). Robustness: (1) logistic regression (logit) on indicator vs linear probability; (2) replace indicator with 3-level ordinal bins (0, 1-3, 4+); (3) exclude high-exposure tail (CSA>15) to test leverage. Confirmatory code: analysis/code/confirmatory_models.py (SRS).\"\nHYP-004,SocialSupport,\"Supportive circles associate with higher self-love.\",I love myself (2l8994l),\"In general, people in my *current* social circles tend to treat me really well (71mn55g)\",\"selfage; gendermale\",\"Non-missing support & outcome\",\"Weighted coefficient on support\",proposed,\"Instrument equivalence confirmed 2025-11-03 via verify_social_support_equivalence.py; predictor now 71mn55g (97.3% coverage). Retain tmt46e6 as legacy variant for sensitivity.\"\n",
      "mode": "text"
    },
    {
      "path": "notebooks/research_notebook.md",
      "content": "# Research Notebook\nUpdated: 2025-11-03T22:05:00Z | Seed: 20251016\n\nReproducibility: run `python analysis/code/bootstrap_setup.py`; env info in `artifacts/session_info.txt`; checksums in `artifacts/checksums.json`.\n\nHypotheses: HYP-001 childhood class \u2191 self-love; HYP-002 current class \u2193 depression; HYP-003 CSA \u2191 anxiety; HYP-004 support \u2191 self-love.\n\n2025-11-03T20:29Z \u2014 Survey design validation confirms no sampling weights/strata/clusters present in `childhoodbalancedpublic_original.csv`; working under simple random sampling assumption. See `qc/survey_design_validation.md` regenerated via `python analysis/code/validate_survey_design.py`.\n\n2025-11-03T20:34Z (Exploratory) \u2014 Generated outcome distributions under SRS assumption via\\\n `python analysis/code/eda_weighted_summaries.py --dataset childhoodbalancedpublic_original.csv --codebook docs/codebook.json --config config/agent_config.yaml --out-summary tables/exploratory_outcome_summary.csv --out-distribution tables/exploratory_outcome_distribution.csv`.\\\n Key findings: self-love skews positive (median=1), while depression/anxiety skew negative (median -1). All categories exceed the small-cell threshold (10). Outputs: `tables/exploratory_outcome_summary.csv`, `tables/exploratory_outcome_distribution.csv`.\n\nTODO: document literature and exploratory findings (labelled \"Exploratory\"); derive CSA indicator prior to PAP freeze. Prepare `papers/main/MANIFEST.md` when manuscript drafting begins.\n\n2025-11-03T20:50Z \u2014 Schema alignment completed via \\\n`python analysis/code/align_codebook_schema.py --dataset childhoodbalancedpublic_original.csv --codebook-in docs/codebook.json --codebook-out docs/codebook.json`.\\\nValidated storage types, allowed ranges, and missingness for six analysis variables; suppressed small cells (<10) and now omit detailed frequency tables to avoid sparse tail disclosure. Details recorded in `qc/schema_alignment.md`.\n\n2025-11-03T20:56Z (QC) \u2014 Profiled hypothesis-relevant missingness via \\\n`python analysis/code/profile_missingness.py --dataset childhoodbalancedpublic_original.csv --codebook docs/codebook.json --hypotheses analysis/hypotheses.csv --config config/agent_config.yaml --out-csv tables/missingness_profile.csv --out-patterns tables/missingness_patterns.csv`.\\\n Suppressed cell counts <10; see `tables/missingness_profile.csv` (+ `.meta.json`) and `tables/missingness_patterns.csv`. Social support predictor `In general, people in my *current* social circles tend treat me really well (tmt46e6)` exhibits 97.35% missingness\u2014flagged for feasibility review. At that point `CSA_score_indicator` was absent in raw data, motivating derivation task T-006 prior to PAP freeze.\n\n2025-11-03T21:05Z (Derived) \u2014 Established canonical data folders (`data/raw`, `data/clean`) and derived CSA exposure indicator via \\\n`python analysis/code/derive_csa_indicator.py --dataset data/raw/childhoodbalancedpublic_original.csv --out-dataset data/clean/childhoodbalancedpublic_with_csa_indicator.csv --out-distribution tables/csa_indicator_distribution.csv --config config/agent_config.yaml --codebook-in docs/codebook.json --codebook-out docs/codebook.json`.\\\nOutput dataset stored at `data/clean/childhoodbalancedpublic_with_csa_indicator.csv`; distribution table `tables/csa_indicator_distribution.csv` confirms 22.31% report any CSA (no cells <10). Updated `docs/codebook.json` with new binary predictor metadata and refreshed `artifacts/checksums.json`. PAP robustness section expanded for HYP-001/HYP-003 (see `analysis/pre_analysis_plan.md`).\n\n2025-11-03T21:35Z (Exploratory) \u2014 Assessed feasibility of the social support predictor for HYP-004 via \\\n`python analysis/code/social_support_missingness.py --dataset data/clean/childhoodbalancedpublic_with_csa_indicator.csv --out-csv tables/social_support_missingness.csv --config config/agent_config.yaml`.\\\n Key finding: original item (`...tend treat me really well (tmt46e6)`) covers only 383 respondents (97.35% missing), while an instrument twin (`...tend to treat me really well (71mn55g)`) covers 14,054 respondents. Responses do not overlap, suggesting form-version routing. Recommendation logged in `qc/social_support_feasibility.md` to pivot HYP-004 to the high-coverage item pending instrument confirmation.\n\n2025-11-03T22:05Z (QC) \u2014 Verified instrument equivalence across the tmt46e6 and 71mn55g social-support items via \\\n`python analysis/code/verify_social_support_equivalence.py --dataset data/clean/childhoodbalancedpublic_with_csa_indicator.csv --out-summary tables/social_support_equivalence_summary.csv --out-distribution tables/social_support_equivalence_distributions.csv --out-overlap tables/social_support_instrument_overlap.csv --config config/agent_config.yaml --columns \"In general, people in my *current* social circles tend treat me really well (tmt46e6)\" \"In general, people in my *current* social circles tend to treat me really well (71mn55g)\"`.\\\n Findings: identical 7-point scales (\u22123 to +3), shared prompt wording apart from insertion of \u201cto,\u201d and mutually exclusive routing (no respondents with both non-missing). Distribution tables suppress cells <10 as required. Documented evidence in `qc/social_support_equivalence.md`; updated codebook and hypothesis registry to pivot HYP-004 to instrument 71mn55g.\n\n2025-11-03T22:45Z (Planning) \u2014 Drafted confirmatory model equations and executable skeleton via \\\n`python analysis/code/confirmatory_models.py --dataset data/clean/childhoodbalancedpublic_with_csa_indicator.csv --config config/agent_config.yaml --survey-design docs/survey_design.yaml --hypotheses HYP-001 HYP-003 --results-csv analysis/results.csv --overwrite`.\\\n Outcome: PAP now records explicit model statements for HYP-001 and HYP-003, and hypothesis registry flags them `in_PAP`. The script writes deterministic HC3 OLS outputs seeded at 20251016 and will feed `analysis/results.csv` post-freeze. Next step: freeze PAP and tag commit prior to confirmatory execution.\n",
      "mode": "text"
    },
    {
      "path": "artifacts/state.json",
      "content": "{\n  \"backlog\": [\n    {\n      \"description\": \"Validate survey weights and replicate design\",\n      \"id\": \"T-001\",\n      \"priority\": 1,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Exploratory weighted summaries for key outcomes\",\n      \"id\": \"T-002\",\n      \"priority\": 1,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Align codebook schema with dataset\",\n      \"id\": \"T-003\",\n      \"priority\": 2,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Profile missingness patterns for key variables\",\n      \"id\": \"T-004\",\n      \"priority\": 2,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Draft robustness checks for priority hypotheses\",\n      \"id\": \"T-005\",\n      \"priority\": 3,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Derive CSA_score_indicator and validate distribution\",\n      \"id\": \"T-006\",\n      \"priority\": 2,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Assess feasibility of social support predictor given 97% missingness\",\n      \"id\": \"T-007\",\n      \"priority\": 2,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Draft confirmatory model equations/code skeleton for PAP freeze\",\n      \"id\": \"T-008\",\n      \"priority\": 3,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Verify instrument equivalence for social support items (tmt46e6 vs 71mn55g)\",\n      \"id\": \"T-009\",\n      \"priority\": 2,\n      \"status\": \"completed\"\n    },\n    {\n      \"description\": \"Freeze PAP and tag reproducibility checkpoint\",\n      \"id\": \"T-010\",\n      \"priority\": 1,\n      \"status\": \"pending\"\n    },\n    {\n      \"description\": \"Plan FDR procedure and robustness execution scripts\",\n      \"id\": \"T-011\",\n      \"priority\": 2,\n      \"status\": \"pending\"\n    }\n  ],\n  \"bootstrap_complete\": true,\n  \"last_updated\": \"2025-11-03T22:45:00+00:00\",\n  \"loop_counter\": 8,\n  \"next_actions\": [\n    {\n      \"description\": \"Freeze PAP and tag reproducibility checkpoint\",\n      \"id\": \"T-010\",\n      \"priority\": 1\n    }\n  ],\n  \"notes\": \"Confirmatory OLS skeleton implemented for HYP-001 and HYP-003; PAP now contains explicit model equations and command paths.\",\n  \"pap_status\": \"draft\",\n  \"priority_hypotheses\": [\n    \"HYP-001\",\n    \"HYP-003\"\n  ],\n  \"seed\": 20251016,\n  \"total_loops\": 30\n}\n",
      "mode": "text"
    },
    {
      "path": "analysis/decision_log.csv",
      "content": "ts,action,inputs,rationale_short,code_path,outputs,status\n2025-11-03T20:01:43Z,bootstrap,docs/codebook.json;docs/survey_design.yaml;config/agent_config.yaml,\"Initialized bootstrap scaffolding, hypotheses, PAP draft, and regen script.\",N/A,artifacts/state.json;analysis/hypotheses.csv;analysis/pre_analysis_plan.md,success\n2025-11-03T20:18:32Z,validate_design,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,\"Confirmed no survey weights; default to SRS.\",analysis/code/validate_survey_design.py,docs/survey_design.yaml;qc/survey_design_validation.md,success\n2025-11-03T20:23:05Z,regen_design,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,\"Regenerated design artifacts after script refactor.\",analysis/code/validate_survey_design.py,docs/survey_design.yaml;qc/survey_design_validation.md,success\n2025-11-03T20:24:59Z,regen_design,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,\"Refined validation script for leaner reproducibility footprint.\",analysis/code/validate_survey_design.py,docs/survey_design.yaml;qc/survey_design_validation.md,success\n2025-11-03T20:26:59Z,regen_design,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,\"Re-executed lean validation script to refresh artifacts.\",analysis/code/validate_survey_design.py,docs/survey_design.yaml;qc/survey_design_validation.md,success\n2025-11-03T20:29:10Z,regen_design,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,\"Compressed validation script and refreshed outputs.\",analysis/code/validate_survey_design.py,docs/survey_design.yaml;qc/survey_design_validation.md,success\n2025-11-03T20:29:10Z,regen_design,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,Compressed validation script and refreshed outputs.,analysis/code/validate_survey_design.py,docs/survey_design.yaml;qc/survey_design_validation.md,success\n2025-11-03T20:34:14Z,exploratory_summary,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,\"Generated exploratory outcome summaries under SRS.\",analysis/code/eda_weighted_summaries.py,tables/exploratory_outcome_summary.csv;tables/exploratory_outcome_distribution.csv,success\n2025-11-03T20:34:14Z,exploratory_summary,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,Generated exploratory outcome summaries under SRS.,analysis/code/eda_weighted_summaries.py,tables/exploratory_outcome_summary.csv;tables/exploratory_outcome_distribution.csv,success\n2025-11-03T20:44:20Z,schema_alignment,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,Regenerated codebook schema with suppressed small cells.,analysis/code/align_codebook_schema.py,docs/codebook.json;qc/schema_alignment.md,success\n2025-11-03T20:47:13Z,schema_alignment,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,Trimmed published frequencies to limit sparse tail disclosure.,analysis/code/align_codebook_schema.py,docs/codebook.json;qc/schema_alignment.md,success\n2025-11-03T20:48:21Z,schema_alignment,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,Refreshed codebook notes to current timestamp.,analysis/code/align_codebook_schema.py,docs/codebook.json;qc/schema_alignment.md,success\n2025-11-03T20:50:32Z,schema_alignment,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,Streamlined codebook to summary-only metadata for disclosure control.,analysis/code/align_codebook_schema.py,docs/codebook.json;qc/schema_alignment.md,success\n2025-11-03T20:50:32Z,schema_alignment,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml,Streamlined codebook to summary-only metadata for disclosure control.,analysis/code/align_codebook_schema.py,docs/codebook.json;qc/schema_alignment.md,success\n2025-11-03T20:56:41Z,missingness_profile,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml;analysis/hypotheses.csv,\"Profiled hypothesis missingness; suppressed <10 cells.\",analysis/code/profile_missingness.py,tables/missingness_profile.csv;tables/missingness_patterns.csv;tables/missingness_profile.meta.json,success\n2025-11-03T20:56:41Z,missingness_profile,childhoodbalancedpublic_original.csv;docs/codebook.json;config/agent_config.yaml;analysis/hypotheses.csv,Profiled hypothesis missingness; suppressed <10 cells.,analysis/code/profile_missingness.py,tables/missingness_profile.csv;tables/missingness_patterns.csv;tables/missingness_profile.meta.json,success\n2025-11-03T21:06:24Z,derive_csa_indicator,data/raw/childhoodbalancedpublic_original.csv;config/agent_config.yaml;docs/codebook.json;analysis/pre_analysis_plan.md,Derived CSA indicator and expanded robustness plans.,analysis/code/derive_csa_indicator.py,data/clean/childhoodbalancedpublic_with_csa_indicator.csv;tables/csa_indicator_distribution.csv;docs/codebook.json;analysis/pre_analysis_plan.md;analysis/hypotheses.csv;notebooks/research_notebook.md;qc/data_checks.md,success\n2025-11-03T21:06:24Z,derive_csa_indicator,data/raw/childhoodbalancedpublic_original.csv;config/agent_config.yaml;docs/codebook.json;analysis/pre_analysis_plan.md,Derived CSA indicator and expanded robustness plans.,analysis/code/derive_csa_indicator.py,data/clean/childhoodbalancedpublic_with_csa_indicator.csv;tables/csa_indicator_distribution.csv;docs/codebook.json;analysis/pre_analysis_plan.md;analysis/hypotheses.csv;notebooks/research_notebook.md;qc/data_checks.md,success\n2025-11-03T21:35:00Z,support_feasibility,data/clean/childhoodbalancedpublic_with_csa_indicator.csv;config/agent_config.yaml,Profiled social support coverage; recommended alternate item.,analysis/code/social_support_missingness.py,tables/social_support_missingness.csv;qc/social_support_feasibility.md;analysis/hypotheses.csv;notebooks/research_notebook.md;artifacts/state.json,success\n2025-11-03T22:05:00Z,instrument_equivalence,data/clean/childhoodbalancedpublic_with_csa_indicator.csv;config/agent_config.yaml;docs/codebook.json;analysis/hypotheses.csv,\"Verified social-support instrument alignment and pivoted predictor to 71mn55g.\",analysis/code/verify_social_support_equivalence.py,tables/social_support_equivalence_summary.csv;tables/social_support_equivalence_distributions.csv;tables/social_support_instrument_overlap.csv;qc/social_support_equivalence.md;docs/codebook.json;analysis/hypotheses.csv;analysis/pre_analysis_plan.md;notebooks/research_notebook.md;artifacts/state.json,success\n2025-11-03T22:45:00Z,confirmatory_model_skeleton,data/clean/childhoodbalancedpublic_with_csa_indicator.csv;config/agent_config.yaml;docs/survey_design.yaml;analysis/hypotheses.csv;analysis/pre_analysis_plan.md,\"Drafted confirmatory OLS skeleton and updated PAP for freeze readiness.\",analysis/code/confirmatory_models.py,analysis/code/confirmatory_models.py;analysis/pre_analysis_plan.md;analysis/hypotheses.csv;notebooks/research_notebook.md;artifacts/state.json,success\n",
      "mode": "text"
    }
  ],
  "decision_log_row": {
    "ts": "2025-11-03T22:45:00Z",
    "action": "confirmatory_model_skeleton",
    "inputs": [
      "data/clean/childhoodbalancedpublic_with_csa_indicator.csv",
      "config/agent_config.yaml",
      "docs/survey_design.yaml",
      "analysis/hypotheses.csv",
      "analysis/pre_analysis_plan.md"
    ],
    "rationale_short": "Drafted confirmatory OLS skeleton and updated PAP for freeze readiness.",
    "code_path": "analysis/code/confirmatory_models.py",
    "outputs": [
      "analysis/code/confirmatory_models.py",
      "analysis/pre_analysis_plan.md",
      "analysis/hypotheses.csv",
      "notebooks/research_notebook.md",
      "artifacts/state.json"
    ],
    "status": "success"
  },
  "next_actions": [
    {
      "id": "T-010",
      "priority": 1,
      "desc": "Freeze PAP and tag reproducibility checkpoint",
      "estimate_min": "15m"
    },
    {
      "id": "T-011",
      "priority": 2,
      "desc": "Plan FDR procedure and robustness execution scripts",
      "estimate_min": "25m"
    }
  ],
  "state_update": {
    "loop_counter": 8
  },
  "git": {
    "commit": true,
    "message": "feat(pap): add confirmatory model skeleton and registry updates"
  },
  "stop_now": false,
  "stop_reason": "",
  "signals": []
}